{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8be15d8-fa8b-4b4f-94d7-39ed53321abd",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee706056-1bac-4cb0-820e-b9824ebdb12a",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc38be-5625-4c22-b622-dca1d20a2134",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03086336-ee63-4d6a-a1ce-d243006d7057",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e223ac3e-4f39-44fa-a3fe-e1e0badf69ac",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cddaf13-6966-4047-aa87-daebb0727a7b",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268cb62-6e7c-4d79-be7c-d946a22c6923",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b4baf-895a-4feb-9b7e-a15aedf316ad",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73057dbb-7947-47cb-a232-3b73ed6a98c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahim\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahim\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rahim\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rahim\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahim\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8c69b-ce80-4c51-bef1-fa344e72a840",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944eb65-42f7-4a97-bc2a-87f69456a1a4",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f636b4c-6417-4cbc-a15d-da5bdab947e7",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0302abc-6d29-4f75-9023-8bfd18365412",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acfb07-c289-45fc-a4a3-20bcad583eed",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417bbb3f-df8d-45ec-8d6e-8f695d9a4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7df306-0dd0-4566-a376-bad64fbf6455",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b356e-a83e-478a-bd04-da95500e0304",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b368e2-4d3c-4382-9b1c-458be459ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Data Type  Non-Null Count  Missing Values\n",
      "ResponseId              int64           65437               0\n",
      "MainBranch             object           65437               0\n",
      "Age                    object           65437               0\n",
      "Employment             object           65437               0\n",
      "RemoteWork             object           54806           10631\n",
      "...                       ...             ...             ...\n",
      "JobSatPoints_11       float64           29445           35992\n",
      "SurveyLength           object           56182            9255\n",
      "SurveyEase             object           56238            9199\n",
      "ConvertedCompYearly   float64           23435           42002\n",
      "JobSat                float64           29126           36311\n",
      "\n",
      "[114 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Create a summary table\n",
    "summary = pd.DataFrame({\n",
    "    \"Data Type\": df.dtypes,\n",
    "    \"Non-Null Count\": df.count(),\n",
    "    \"Missing Values\": df.isnull().sum()\n",
    "})\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685cdd1b-44d7-40cf-ba9f-ee347f747832",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e527b643-6963-4a64-aab2-297894062fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
      "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
      "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Display summary statistics for numerical columns\n",
    "numeric_summary = df.describe()\n",
    "print(numeric_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca71359-8f5b-4f33-afe9-af011c2eae37",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d423d-4338-423a-ae66-40981cc7809d",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd43fee0-2805-495c-93df-2f93fa2c35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States of America                                11095\n",
      "NaN                                                      6507\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "France                                                   2110\n",
      "Canada                                                   2104\n",
      "Poland                                                   1534\n",
      "Netherlands                                              1449\n",
      "Brazil                                                   1375\n",
      "Italy                                                    1341\n",
      "Australia                                                1260\n",
      "Spain                                                    1123\n",
      "Sweden                                                   1016\n",
      "Russian Federation                                        925\n",
      "Switzerland                                               876\n",
      "Austria                                                   791\n",
      "Czech Republic                                            714\n",
      "Israel                                                    604\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Frequency count of each country\n",
    "country_counts = df['Country'].value_counts(dropna=False)\n",
    "print(country_counts.head(20))  # Top 20 most common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ff9e2-d19e-4175-9997-907c09a94df0",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "196a5909-90b5-4a2b-80cc-ca4427fb97f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Primary/elementary school'\n",
      " 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      " 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)'\n",
      " 'Some college/university study without earning a degree'\n",
      " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)'\n",
      " 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Something else' nan]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Check unique education levels first\n",
    "print(df['EdLevel'].unique())\n",
    "\n",
    "# Define mapping\n",
    "education_mapping = {\n",
    "    \"Bachelor’s degree (B.A., B.S., B.Eng., etc.)\": \"Bachelor's degree\",\n",
    "    \"Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\": \"Master's degree\",\n",
    "    \"Professional degree (JD, MD, etc.)\": \"Professional degree\",\n",
    "    \"Some college/university study without earning a degree\": \"Some college\",\n",
    "    \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\": \"High school\",\n",
    "    # Add others as needed\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['EdLevel'] = df['EdLevel'].replace(education_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f7396f-8152-454d-b0d6-ee70eaba540d",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e675dd9-b427-4c7a-92c2-b711a8ebb6a0",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13bded1e-c766-46f0-9015-88228947549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                     EdLevel  \\\n",
      "0  Primary/elementary school   \n",
      "1          Bachelor's degree   \n",
      "2            Master's degree   \n",
      "3               Some college   \n",
      "4                High school   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ...  \\\n",
      "0                                                NaN  ...   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...   \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work;Student, part-time  \\\n",
      "0                                              False                                                                           \n",
      "1                                              False                                                                           \n",
      "2                                              False                                                                           \n",
      "3                                              False                                                                           \n",
      "4                                              False                                                                           \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Retired  \\\n",
      "0                                              False                         \n",
      "1                                              False                         \n",
      "2                                              False                         \n",
      "3                                              False                         \n",
      "4                                              False                         \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Student, part-time  \\\n",
      "0                                              False                                    \n",
      "1                                              False                                    \n",
      "2                                              False                                    \n",
      "3                                              False                                    \n",
      "4                                              False                                    \n",
      "\n",
      "  Employment_Student, full-time;Retired  \\\n",
      "0                                 False   \n",
      "1                                 False   \n",
      "2                                 False   \n",
      "3                                 False   \n",
      "4                                 False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time  \\\n",
      "0                                            False   \n",
      "1                                            False   \n",
      "2                                            False   \n",
      "3                                            False   \n",
      "4                                            False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Employed, part-time  \\\n",
      "0                                              False                     \n",
      "1                                              False                     \n",
      "2                                              False                     \n",
      "3                                              False                     \n",
      "4                                              False                     \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Retired  \\\n",
      "0                                              False         \n",
      "1                                              False         \n",
      "2                                              False         \n",
      "3                                              False         \n",
      "4                                              False         \n",
      "\n",
      "  Employment_Student, part-time  \\\n",
      "0                         False   \n",
      "1                         False   \n",
      "2                         False   \n",
      "3                         False   \n",
      "4                         False   \n",
      "\n",
      "  Employment_Student, part-time;Employed, part-time  \\\n",
      "0                                             False   \n",
      "1                                             False   \n",
      "2                                             False   \n",
      "3                                             False   \n",
      "4                                             False   \n",
      "\n",
      "  Employment_Student, part-time;Retired  \n",
      "0                                 False  \n",
      "1                                 False  \n",
      "2                                 False  \n",
      "3                                 False  \n",
      "4                                 False  \n",
      "\n",
      "[5 rows x 224 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# One-hot encode the 'Employment' column\n",
    "employment_dummies = pd.get_dummies(df['Employment'], prefix='Employment')\n",
    "\n",
    "# Concatenate new columns to the original dataframe\n",
    "df = pd.concat([df, employment_dummies], axis=1)\n",
    "\n",
    "# Preview result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d75d2-209f-4c56-b14e-b2f8037e76d7",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167edac3-f763-4689-89f9-c2b499fe6ceb",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9b722d-ab02-4316-a64c-96fd10d57f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 columns with the most missing values:\n",
      "AINextMuch less integrated       64289\n",
      "AINextLess integrated            63082\n",
      "AINextNo change                  52939\n",
      "AINextMuch more integrated       51999\n",
      "EmbeddedAdmired                  48704\n",
      "EmbeddedWantToWorkWith           47837\n",
      "EmbeddedHaveWorkedWith           43223\n",
      "ConvertedCompYearly              42002\n",
      "AIToolNot interested in Using    41023\n",
      "AINextMore integrated            41009\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Count missing values per column\n",
    "missing_counts = df.isnull().sum()\n",
    "\n",
    "# Sort descending and show top 10\n",
    "top_missing = missing_counts.sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 columns with the most missing values:\")\n",
    "print(top_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494af17-d786-412c-8fa5-93007c842385",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4dc8e5-d3d2-449d-ae4e-022bd8ee36e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in ConvertedCompYearly: 42002\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Check for missing values in ConvertedCompYearly\n",
    "missing_count = df['ConvertedCompYearly'].isnull().sum()\n",
    "print(f\"Missing values in ConvertedCompYearly: {missing_count}\")\n",
    "\n",
    "# Impute with mean\n",
    "df['ConvertedCompYearly_MeanImputed'] = df['ConvertedCompYearly'].fillna(df['ConvertedCompYearly'].mean())\n",
    "\n",
    "# Or, to impute with median instead:\n",
    "df['ConvertedCompYearly_MedianImputed'] = df['ConvertedCompYearly'].fillna(df['ConvertedCompYearly'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa6dd5-e442-4042-8e0b-7b047c5271c7",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e8de2f3-b9f2-4b54-8545-cfab7573a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value in RemoteWork: Hybrid (some remote, some in-person)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Find the most frequent value (mode) in the 'RemoteWork' column\n",
    "most_frequent = df['RemoteWork'].mode()[0]\n",
    "print(f\"Most frequent value in RemoteWork: {most_frequent}\")\n",
    "\n",
    "# Impute missing values with the mode\n",
    "df['RemoteWork_Imputed'] = df['RemoteWork'].fillna(most_frequent)\n",
    "\n",
    "# Check that missing values are gone\n",
    "print(df['RemoteWork_Imputed'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df590266-80ce-41e6-aec8-0e535b770629",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac8b9d-3b1a-472f-b49a-d8d0299204dc",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "241cb998-7b86-412a-b45c-9463c1bbf02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rahim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/41.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/41.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.1/41.0 MB 11.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.4/41.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.8/41.0 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/41.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.8/41.0 MB 11.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 19.1/41.0 MB 11.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.8/41.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.1/41.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.5/41.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.8/41.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.5/41.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.8/41.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.9/41.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.5/41.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Use imputed column if available\n",
    "scaler = MinMaxScaler()\n",
    "df['ConvertedCompYearly_MinMax'] = scaler.fit_transform(\n",
    "    df[['ConvertedCompYearly_MeanImputed']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556a89e-8ab3-4eaa-9d75-ced79f89ed2c",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5523f80b-9bcd-4761-a6ad-4f4705687f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Log\n",
      "0                  NaN                11.363918\n",
      "1                  NaN                11.363918\n",
      "2                  NaN                11.363918\n",
      "3                  NaN                11.363918\n",
      "4                  NaN                11.363918\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "\n",
    "# Use the mean-imputed column for stability\n",
    "df['ConvertedCompYearly_Log'] = np.log1p(df['ConvertedCompYearly_MeanImputed'])\n",
    "\n",
    "# Preview the result\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_Log']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04a76c-224c-4182-9f4c-ff0ed5bac396",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd7cc2-4615-4c03-a2a9-ed6a30ef2556",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "036d111c-2aac-4f34-9995-5d9fc75b1053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  YearsCodePro  YearsCodePro_Num ExperienceLevel\n",
      "0          NaN               NaN         Unknown\n",
      "1           17              17.0          Expert\n",
      "2           27              27.0          Expert\n",
      "3          NaN               NaN         Unknown\n",
      "4          NaN               NaN         Unknown\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# First, handle possible non-numeric values in YearsCodePro (like 'Less than 1 year')\n",
    "def convert_years(val):\n",
    "    if val == 'Less than 1 year':\n",
    "        return 0.5\n",
    "    elif val == 'More than 50 years':\n",
    "        return 51\n",
    "    else:\n",
    "        try:\n",
    "            return float(val)\n",
    "        except:\n",
    "            return np.nan  # fallback\n",
    "\n",
    "# Apply conversion\n",
    "df['YearsCodePro_Num'] = df['YearsCodePro'].apply(convert_years)\n",
    "\n",
    "# Create experience levels\n",
    "def map_experience(years):\n",
    "    if pd.isnull(years):\n",
    "        return 'Unknown'\n",
    "    elif years < 3:\n",
    "        return 'Beginner'\n",
    "    elif years < 8:\n",
    "        return 'Intermediate'\n",
    "    elif years < 15:\n",
    "        return 'Advanced'\n",
    "    else:\n",
    "        return 'Expert'\n",
    "\n",
    "df['ExperienceLevel'] = df['YearsCodePro_Num'].apply(map_experience)\n",
    "\n",
    "# Preview the result\n",
    "print(df[['YearsCodePro', 'YearsCodePro_Num', 'ExperienceLevel']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9db65-501b-4f0a-b514-5b77fe7172b1",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10613a56-101f-4d4e-8d03-08bb7c5f54bc",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b9608-d5e2-4b31-a8ce-09231fafce5f",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
